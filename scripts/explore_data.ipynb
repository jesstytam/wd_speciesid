{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab749df",
   "metadata": {},
   "source": [
    "# 1. Loading & counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583d8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c2e739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Site</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Moon Phase</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Number</th>\n",
       "      <th>Pouch status</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFGrid01874</td>\n",
       "      <td>2021-05-24 17-58-33 M 1_3.JPG</td>\n",
       "      <td>PCAM01</td>\n",
       "      <td>Park</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>17:58:33</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFGrid01880</td>\n",
       "      <td>2021-05-24 18-02-50 M 2_3.JPG</td>\n",
       "      <td>PCAM01</td>\n",
       "      <td>Park</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>18:02:50</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFGrid01881</td>\n",
       "      <td>2021-05-24 22-38-03 M 1_3.JPG</td>\n",
       "      <td>PCAM01</td>\n",
       "      <td>Park</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>22:38:03</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFGrid01890</td>\n",
       "      <td>2021-05-24 21-27-09 M 1_3.JPG</td>\n",
       "      <td>PCAM01</td>\n",
       "      <td>Park</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>21:27:09</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFGrid01891</td>\n",
       "      <td>2021-05-24 21-26-03 M 3_3.JPG</td>\n",
       "      <td>PCAM01</td>\n",
       "      <td>Park</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>21:26:03</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>BFGrid14116</td>\n",
       "      <td>2021-12-27 01-44-43 M 1_3.JPG</td>\n",
       "      <td>WCAM15</td>\n",
       "      <td>WTZ</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>01:44:43</td>\n",
       "      <td>Last Quarter</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15352</th>\n",
       "      <td>BFGrid14117</td>\n",
       "      <td>2021-12-27 03-05-32 M 1_3.JPG</td>\n",
       "      <td>WCAM15</td>\n",
       "      <td>WTZ</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>03:05:32</td>\n",
       "      <td>Last Quarter</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15353</th>\n",
       "      <td>BFGrid14494</td>\n",
       "      <td>2022-01-14 23-20-32 M 1_3.JPG</td>\n",
       "      <td>WCAM15</td>\n",
       "      <td>WTZ</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>23:20:32</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15354</th>\n",
       "      <td>BFGrid14534</td>\n",
       "      <td>2022-01-15 02-37-22 M 3_3.JPG</td>\n",
       "      <td>WCAM15</td>\n",
       "      <td>WTZ</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>02:37:22</td>\n",
       "      <td>Waxing Gibbous</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15355</th>\n",
       "      <td>BFGrid14587</td>\n",
       "      <td>2022-01-21 00-55-43 M 2_3.JPG</td>\n",
       "      <td>WCAM15</td>\n",
       "      <td>WTZ</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>00:55:43</td>\n",
       "      <td>Waning Gibbous</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red Kangaroo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15356 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RecordID                     Image Name    Site Treatment  \\\n",
       "0      BFGrid01874  2021-05-24 17-58-33 M 1_3.JPG  PCAM01      Park   \n",
       "1      BFGrid01880  2021-05-24 18-02-50 M 2_3.JPG  PCAM01      Park   \n",
       "2      BFGrid01881  2021-05-24 22-38-03 M 1_3.JPG  PCAM01      Park   \n",
       "3      BFGrid01890  2021-05-24 21-27-09 M 1_3.JPG  PCAM01      Park   \n",
       "4      BFGrid01891  2021-05-24 21-26-03 M 3_3.JPG  PCAM01      Park   \n",
       "...            ...                            ...     ...       ...   \n",
       "15351  BFGrid14116  2021-12-27 01-44-43 M 1_3.JPG  WCAM15       WTZ   \n",
       "15352  BFGrid14117  2021-12-27 03-05-32 M 1_3.JPG  WCAM15       WTZ   \n",
       "15353  BFGrid14494  2022-01-14 23-20-32 M 1_3.JPG  WCAM15       WTZ   \n",
       "15354  BFGrid14534  2022-01-15 02-37-22 M 3_3.JPG  WCAM15       WTZ   \n",
       "15355  BFGrid14587  2022-01-21 00-55-43 M 2_3.JPG  WCAM15       WTZ   \n",
       "\n",
       "            Date      Time      Moon Phase  Temp Comments  Number  \\\n",
       "0     2021-05-24  17:58:33  Waxing Gibbous    21      NaN     2.0   \n",
       "1     2021-05-24  18:02:50  Waxing Gibbous    21      NaN     1.0   \n",
       "2     2021-05-24  22:38:03  Waxing Gibbous    16      NaN     2.0   \n",
       "3     2021-05-24  21:27:09  Waxing Gibbous    17      NaN     2.0   \n",
       "4     2021-05-24  21:26:03  Waxing Gibbous    17      NaN     2.0   \n",
       "...          ...       ...             ...   ...      ...     ...   \n",
       "15351 2021-12-27  01:44:43    Last Quarter    23      NaN     1.0   \n",
       "15352 2021-12-27  03:05:32    Last Quarter    22      NaN     1.0   \n",
       "15353 2022-01-14  23:20:32  Waxing Gibbous    23      NaN     1.0   \n",
       "15354 2022-01-15  02:37:22  Waxing Gibbous    19      NaN     1.0   \n",
       "15355 2022-01-21  00:55:43  Waning Gibbous    24      NaN     2.0   \n",
       "\n",
       "       Pouch status       Species  \n",
       "0               NaN  Red Kangaroo  \n",
       "1               NaN  Red Kangaroo  \n",
       "2               NaN  Red Kangaroo  \n",
       "3               NaN  Red Kangaroo  \n",
       "4               NaN  Red Kangaroo  \n",
       "...             ...           ...  \n",
       "15351           NaN  Red Kangaroo  \n",
       "15352           NaN  Red Kangaroo  \n",
       "15353           NaN  Red Kangaroo  \n",
       "15354           NaN  Red Kangaroo  \n",
       "15355           NaN  Red Kangaroo  \n",
       "\n",
       "[15356 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get excel file\n",
    "xlsx = pd.read_excel('~/wd_speciesid/data/raw/BtF-information/Beyond_the_Fence_ALL_TAGS_to_Feb22.xlsx',\n",
    "                     header=1)\n",
    "xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a03757e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Red Kangaroo', 'Kangaroo', 'Dingo', 'Rabbit', 'Cat', 'Emu',\n",
       "       'Bird', 'Pig', 'Euro', 'Fox', 'Echidna', 'Western Grey Kangaroo',\n",
       "       'Small mammal', 'Other', 'Goat'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0118b6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Red Kangaroo             8776\n",
       "Cat                      2378\n",
       "Kangaroo                 1375\n",
       "Rabbit                   1218\n",
       "Bird                      539\n",
       "Small mammal              457\n",
       "Western Grey Kangaroo     165\n",
       "Dingo                     131\n",
       "Emu                       120\n",
       "Euro                       56\n",
       "Pig                        50\n",
       "Fox                        35\n",
       "Goat                       25\n",
       "Echidna                    18\n",
       "Other                      13\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d0c362",
   "metadata": {},
   "source": [
    "# 2 Deciding how to split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89f33ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Kangaroo : min date is 2021-02-10 00:00:00 & max date is 2022-02-17 00:00:00\n",
      "Kangaroo : min date is 2021-02-11 00:00:00 & max date is 2022-02-12 00:00:00\n",
      "Dingo : min date is 2021-04-03 00:00:00 & max date is 2022-02-17 00:00:00\n",
      "Rabbit : min date is 2021-02-07 00:00:00 & max date is 2022-02-15 00:00:00\n",
      "Cat : min date is 2021-02-11 00:00:00 & max date is 2022-02-18 00:00:00\n",
      "Emu : min date is 2021-02-14 00:00:00 & max date is 2022-02-15 00:00:00\n",
      "Bird : min date is 2021-02-15 00:00:00 & max date is 2021-10-04 00:00:00\n",
      "Pig : min date is 2021-03-31 00:00:00 & max date is 2021-12-14 00:00:00\n",
      "Euro : min date is 2021-06-09 00:00:00 & max date is 2022-01-24 00:00:00\n",
      "Fox : min date is 2021-03-20 00:00:00 & max date is 2021-07-26 00:00:00\n",
      "Echidna : min date is 2021-03-14 00:00:00 & max date is 2021-12-19 00:00:00\n",
      "Western Grey Kangaroo : min date is 2021-04-23 00:00:00 & max date is 2021-12-16 00:00:00\n",
      "Small mammal : min date is 2021-02-14 00:00:00 & max date is 2022-02-13 00:00:00\n",
      "Other : min date is 2021-05-02 00:00:00 & max date is 2021-09-30 00:00:00\n",
      "Goat : min date is 2021-07-18 00:00:00 & max date is 2022-02-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#check the dates\n",
    "for species in xlsx['Species'].unique():\n",
    "    new_df = xlsx[xlsx['Species']==species]\n",
    "    min_date = min(new_df['Date'])\n",
    "    max_date = max(new_df['Date'])\n",
    "    print(species, ': min date is', min_date, '& max date is', max_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f5040b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10029\n",
      "3089\n",
      "2238\n"
     ]
    }
   ],
   "source": [
    "train_entries = xlsx[xlsx['Date']<'2021-10-01 00:00:00'] #Feb2021 to Sep2021\n",
    "print(len(train_entries))\n",
    "val_entries = xlsx[ (xlsx['Date']>'2021-09-30 00:00:00') & (xlsx['Date']<'2021-12-01 00:00:00') ] #Oct2021 to Nov2021\n",
    "print(len(val_entries))\n",
    "test_entries = xlsx[xlsx['Date']>'2021-11-30 00:00:00'] #from Dec2021\n",
    "print(len(test_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "52e43fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Kangaroo : 5159 / 2268 / 1349\n",
      "Kangaroo : 1245 / 67 / 63\n",
      "Dingo : 75 / 8 / 48\n",
      "Rabbit : 790 / 198 / 230\n",
      "Cat : 1425 / 455 / 498\n",
      "Emu : 69 / 27 / 24\n",
      "Bird : 538 / 1 / 0\n",
      "Pig : 47 / 2 / 1\n",
      "Euro : 26 / 25 / 5\n",
      "Fox : 35 / 0 / 0\n",
      "Echidna : 11 / 5 / 2\n",
      "Western Grey Kangaroo : 140 / 22 / 3\n",
      "Small mammal : 438 / 11 / 8\n",
      "Other : 13 / 0 / 0\n",
      "Goat : 18 / 0 / 7\n"
     ]
    }
   ],
   "source": [
    "all_species = xlsx['Species'].unique()\n",
    "\n",
    "for species in all_species:\n",
    "    train = len(train_entries[train_entries['Species']==species])\n",
    "    val = len(val_entries[val_entries['Species']==species])\n",
    "    test = len(test_entries[test_entries['Species']==species])\n",
    "    print(species, ':', train, '/', val, '/', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964276de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Group data by 'Species'\n",
    "grouped = xlsx.groupby('Species')\n",
    "\n",
    "# Initialize dictionaries to store train, validation, and test data\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "# Loop through each species group\n",
    "for species, group in grouped:\n",
    "    # Sort images by date\n",
    "    group = group.sort_values(by='Date')\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_size = len(group)\n",
    "    train_size = int(0.7 * total_size)\n",
    "    val_size = int(0.15 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Split images\n",
    "    train_data.extend(group[:train_size])\n",
    "    val_data.extend(group[train_size:train_size + val_size])\n",
    "    test_data.extend(group[train_size + val_size:])\n",
    "\n",
    "# Create new DataFrames for train, validation, and test sets\n",
    "train_df = pd.DataFrame(train_data)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Now you have separate DataFrames for each split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ffb3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize dictionaries to store train, validation, and test data\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "# Loop through each species group\n",
    "for species in xlsx['Species'].unique():\n",
    "    # Sort images by date\n",
    "    new_df = xlsx[xlsx['Species']==species]\n",
    "    group = new_df.sort_values('Date')\n",
    "\n",
    "    # Calculate split sizes\n",
    "    total_size = len(group)\n",
    "    train_size = int(0.7 * total_size)\n",
    "    val_size = int(0.15 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "\n",
    "    # Split images\n",
    "    train_data.append(group[:train_size])\n",
    "    val_data.append(group[train_size:train_size + val_size])\n",
    "    test_data.append(group[train_size + val_size:])\n",
    "\n",
    "# Create new DataFrames for train, validation, and test sets\n",
    "# train_df = pd.DataFrame(train_data)\n",
    "# val_df = pd.DataFrame(val_data)\n",
    "# test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Now you have separate DataFrames for each split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84b8279b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39;49mDataFrame(train_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv4e/lib/python3.9/site-packages/pandas/core/frame.py:762\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    754\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m             arrays,\n\u001b[1;32m    756\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    763\u001b[0m             data,\n\u001b[1;32m    764\u001b[0m             index,\n\u001b[1;32m    765\u001b[0m             columns,\n\u001b[1;32m    766\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    767\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    768\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    769\u001b[0m         )\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    772\u001b[0m         {},\n\u001b[1;32m    773\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cv4e/lib/python3.9/site-packages/pandas/core/internals/construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    324\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[1;32m    332\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv4e/lib/python3.9/site-packages/pandas/core/internals/construction.py:568\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m# and platform dtype preservation\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(values[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 568\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([convert(v) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m values])\n\u001b[1;32m    569\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(values[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m values[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    570\u001b[0m     \u001b[39m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([convert(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (15,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "train_data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e3f56",
   "metadata": {},
   "source": [
    "## 2.2. Split with scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfd998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train / test\n",
    "X_train, X_test, y_train, y_test \n",
    "    = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#train / val\n",
    " X_train, X_val, y_train, y_val \n",
    "    = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd1fc9",
   "metadata": {},
   "source": [
    "# ?. Moving the images around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33300b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#create parent directory for processed images\n",
    "image_path = '/media/jess/DATA2/PhD/data/wild_deserts/'\n",
    "new_folder = 'processed/'\n",
    "processed_path = os.path.join(image_path, new_folder)\n",
    "try:    \n",
    "    os.mkdir(processed_path)\n",
    "    print('Done!')\n",
    "except:\n",
    "    print('Folder created already!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51498457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder for each species\n",
    "def create_species_folder(species):\n",
    "    species_folder = species + '/'\n",
    "    species_path = os.path.join(processed_path, species_folder)\n",
    "    try:    \n",
    "        os.mkdir(species_path)\n",
    "        print(species + '- Done!')\n",
    "    except:\n",
    "        print('Folder created already!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eebf14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Kangaroo- Done!\n",
      "Kangaroo- Done!\n",
      "Dingo- Done!\n",
      "Rabbit- Done!\n",
      "Cat- Done!\n",
      "Emu- Done!\n",
      "Bird- Done!\n",
      "Pig- Done!\n",
      "Euro- Done!\n",
      "Fox- Done!\n",
      "Echidna- Done!\n",
      "Western Grey Kangaroo- Done!\n",
      "Small mammal- Done!\n",
      "Other- Done!\n",
      "Goat- Done!\n"
     ]
    }
   ],
   "source": [
    "species = xlsx['Species'].unique()\n",
    "for sp in species:\n",
    "    create_species_folder(sp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
